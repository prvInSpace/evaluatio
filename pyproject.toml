[project]
name = "evaluatio"
version = "0.2.0"
description = "A library that contains computationally efficient metrics for the valuation of different NLP systems"
license = "MIT"
readme = "README.md"
authors = [{ name = "Preben Vangberg", email = "prv21fgt@bangor.ac.uk" }]
maintainers = [{ name = "Preben Vangberg", email = "prv21fgt@bangor.ac.uk" }]
requires-python = ">=3.8"
classifiers = [
    "License :: OSI Approved :: MIT License",
    "Topic :: Scientific/Engineering",
    "Programming Language :: Rust",
    "Programming Language :: Python :: Implementation :: CPython",
    "Programming Language :: Python :: Implementation :: PyPy",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
]

[project.urls]
Homepage = "https://codeberg.org/prvinspace/evaluatio"
Documentation = "https://prvinspace.github.io/evaluatio/"
Repository = "https://codeberg.org/prvinspace/evaluatio"
Issues = "https://codeberg.org/prvinspace/evaluatio/issues"

[build-system]
requires = ["maturin>=1.0,<2.0"]
build-backend = "maturin"

[tool.maturin]
manifest-path = "evaluatio-bindings/Cargo.toml"
python-source = "python-src"
module-name = "evaluatio._bindings"
interpreter = "python3.8+"
